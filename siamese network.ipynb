{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d97948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4a9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "margin = 1  # Margin for constrastive loss.\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "#EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ef277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"smalldata/train\"\n",
    "test_path=\"smalldata/test\"\n",
    "val_path=\"smalldata/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30fdf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "\n",
    "    sub_path=train_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(256,256))\n",
    "\n",
    "        x_train.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1543702d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_test=[]\\n\\nfor folder in os.listdir(test_path):\\n\\n    sub_path=test_path+\"/\"+folder\\n\\n    for img in os.listdir(sub_path):\\n\\n        image_path=sub_path+\"/\"+img\\n\\n        img_arr=cv2.imread(image_path)\\n\\n        img_arr=cv2.resize(img_arr,(256,256))\\n\\n        x_test.append(img_arr)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=[]\n",
    "\n",
    "for folder in os.listdir(test_path):\n",
    "\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(256,256))\n",
    "\n",
    "        x_test.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b1f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=[]\n",
    "\n",
    "for folder in os.listdir(val_path):\n",
    "\n",
    "    sub_path=val_path+\"/\"+folder\n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(256,256))\n",
    "\n",
    "        x_val.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dcac685",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "#test_x=np.array(x_test)\n",
    "val_x=np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9531e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_x=train_x/255.0\\ntest_x=test_x/255.0\\nval_x=val_x/255.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ddd9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ee7d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (256, 256),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'sparse')\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (256, 256),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (256, 256),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'sparse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b45e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=training_set.classes\n",
    "test_y=test_set.classes\n",
    "val_y=val_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "217797fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tomato___Early_blight': 0,\n",
       " 'Tomato___Late_blight': 1,\n",
       " 'Tomato___Leaf_Mold': 2,\n",
       " 'Tomato___Tomato_mosaic_virus': 3,\n",
       " 'Tomato___healthy': 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a2abb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), (500,), (500,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape,test_y.shape,val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d86e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x= train_x.astype(\"uint8\")\n",
    "#test_x= test_x.astype(\"uint8\")\n",
    "val_x= val_x.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b1dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_val = train_x[:3000], train_x[3000:]\n",
    "#y_train, y_val = train_y[:3000], train_y[3000:]\n",
    "#del train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfd929c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(x, y):\n",
    "    \"\"\"Creates a tuple containing image pairs with corresponding label.\n",
    "\n",
    "    Arguments:\n",
    "        x: List containing images, each index in this list corresponds to one image.\n",
    "        y: List containing labels, each label with datatype of `int`.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing two numpy arrays as (pairs_of_samples, labels),\n",
    "        where pairs_of_samples' shape is (2len(x), 2,n_features_dims) and\n",
    "        labels are a binary array of shape (2len(x)).\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = max(y) + 1\n",
    "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    for idx1 in range(len(x)):\n",
    "        # add a matching example\n",
    "        x1 = x[idx1]\n",
    "        label1 = y[idx1]\n",
    "        idx2 = random.choice(digit_indices[label1])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [1]\n",
    "\n",
    "        # add a non-matching example\n",
    "        label2 = random.randint(0, num_classes - 1)\n",
    "        while label2 == label1:\n",
    "            label2 = random.randint(0, num_classes - 1)\n",
    "\n",
    "        idx2 = random.choice(digit_indices[label2])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1, x2]]\n",
    "        labels += [0]\n",
    "\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "386ce7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = make_pairs(train_x, train_y)\n",
    "del train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fba6eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# make test pairs\\npairs_test, labels_test = make_pairs(x_test, y_test)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# make test pairs\n",
    "pairs_test, labels_test = make_pairs(x_test, y_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599a9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make validation pairs\n",
    "pairs_val, labels_val = make_pairs(val_x, val_y)\n",
    "del val_x,val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7108f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = pairs_train[:, 0]  # x_train_1.shape is (60000, 28, 28)\n",
    "x_train_2 = pairs_train[:, 1]\n",
    "del pairs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035dadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_1 = pairs_val[:, 0]  # x_val_1.shape = (60000, 28, 28)\n",
    "x_val_2 = pairs_val[:, 1]\n",
    "del pairs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cf95fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Creates a plot of pairs and labels, and prediction if it's test dataset.\n",
    "\n",
    "    Arguments:\n",
    "        pairs: Numpy Array, of pairs to visualize, having shape\n",
    "               (Number of pairs, 2, 28, 28).\n",
    "        to_show: Int, number of examples to visualize (default is 6)\n",
    "                `to_show` must be an integral multiple of `num_col`.\n",
    "                 Otherwise it will be trimmed if it is greater than num_col,\n",
    "                 and incremented if if it is less then num_col.\n",
    "        num_col: Int, number of images in one row - (default is 3)\n",
    "                 For test and train respectively, it should not exceed 3 and 7.\n",
    "        predictions: Numpy Array of predictions with shape (to_show, 1) -\n",
    "                     (default is None)\n",
    "                     Must be passed when test=True.\n",
    "        test: Boolean telling whether the dataset being visualized is\n",
    "              train dataset or test dataset - (default False).\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "        # Define num_row\n",
    "    # If to_show % num_col != 0\n",
    "    #    trim to_show,\n",
    "    #       to trim to_show limit num_row to the point where\n",
    "    #       to_show % num_col == 0\n",
    "    #\n",
    "    # If to_show//num_col == 0\n",
    "    #    then it means num_col is greater then to_show\n",
    "    #    increment to_show\n",
    "    #       to increment to_show set num_row to 1\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "\n",
    "    # `to_show` must be an integral multiple of `num_col`\n",
    "    #  we found num_row and we have num_col\n",
    "    #  to increment or decrement to_show\n",
    "    #  to make it integral multiple of `num_col`\n",
    "    #  simply set it equal to num_row * num_col\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    # Plot the images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5, 5))\n",
    "    for i in range(to_show):\n",
    "\n",
    "        # If the number of rows is 1, the axes array is one-dimensional\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        ax.imshow(tf.concat([pairs[i][0], pairs[i][1]], axis=1), cmap=\"gray\")\n",
    "        ax.set_axis_off()\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "    if test:\n",
    "        plt.tight_layout(rect=(0, 0, 1.9, 1.9), w_pad=0.0)\n",
    "    else:\n",
    "        plt.tight_layout(rect=(0, 0, 1.5, 1.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14f03e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize(pairs_train[:-1], labels_train[:-1], to_show=4, num_col=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6433edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "input = layers.Input((256, 256, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(4, (5, 5), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16, (5, 5), activation=\"tanh\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(10, activation=\"tanh\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((256, 256, 3))\n",
    "input_2 = layers.Input((256, 256, 3))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "993650a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "  Arguments:\n",
    "      margin: Integer, defines the baseline for distance for which pairs\n",
    "              should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "  Returns:\n",
    "      'constrastive_loss' function with data ('margin') attached.\n",
    "  \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "      Arguments:\n",
    "          y_true: List of labels, each label is of type float32.\n",
    "          y_pred: List of predictions of same length as of y_true,\n",
    "                  each label is of type float32.\n",
    "\n",
    "      Returns:\n",
    "          A tensor containing constrastive loss as floating point value.\n",
    "      \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9056cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model (Functional)             (None, 10)           835446      ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['model[0][0]',                  \n",
      "                                                                  'model[1][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 1)           4           ['lambda[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 835,452\n",
      "Trainable params: 716,372\n",
      "Non-trainable params: 119,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfd0e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpus = tf.config.list_physical_devices(\\'GPU\\')\\nif gpus:\\n  # Restrict TensorFlow to only use the first GPU\\n  try:\\n    tf.config.set_visible_devices(gpus[0], \\'GPU\\')\\n    logical_gpus = tf.config.list_logical_devices(\\'GPU\\')\\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\\n  except RuntimeError as e:\\n    # Visible devices must be set before GPUs have been initialized\\n    print(e)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "321212e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 5s 74ms/step - loss: 0.2610 - accuracy: 0.4610 - val_loss: 0.2564 - val_accuracy: 0.4960\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2568 - accuracy: 0.4660 - val_loss: 0.2616 - val_accuracy: 0.4650\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.2567 - accuracy: 0.4690 - val_loss: 0.2573 - val_accuracy: 0.4570\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2561 - accuracy: 0.4760 - val_loss: 0.2564 - val_accuracy: 0.4780\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2556 - accuracy: 0.4730 - val_loss: 0.2545 - val_accuracy: 0.4810\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2525 - accuracy: 0.4950 - val_loss: 0.2543 - val_accuracy: 0.4780\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2512 - accuracy: 0.4970 - val_loss: 0.2534 - val_accuracy: 0.5010\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2511 - accuracy: 0.4920 - val_loss: 0.2529 - val_accuracy: 0.4800\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2514 - accuracy: 0.4890 - val_loss: 0.2538 - val_accuracy: 0.4860\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2510 - accuracy: 0.5060 - val_loss: 0.2517 - val_accuracy: 0.5020\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 2s 58ms/step - loss: 0.2509 - accuracy: 0.5050 - val_loss: 0.2515 - val_accuracy: 0.4940\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2512 - accuracy: 0.4820 - val_loss: 0.2506 - val_accuracy: 0.4870\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2507 - accuracy: 0.4850 - val_loss: 0.2511 - val_accuracy: 0.4950\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2508 - accuracy: 0.4930 - val_loss: 0.2508 - val_accuracy: 0.4910\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2504 - accuracy: 0.5000 - val_loss: 0.2512 - val_accuracy: 0.4800\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2517 - accuracy: 0.4620 - val_loss: 0.2513 - val_accuracy: 0.4890\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2507 - accuracy: 0.4730 - val_loss: 0.2506 - val_accuracy: 0.5050\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2507 - accuracy: 0.4440 - val_loss: 0.2505 - val_accuracy: 0.4430\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2503 - accuracy: 0.4580 - val_loss: 0.2500 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2501 - accuracy: 0.4770 - val_loss: 0.2500 - val_accuracy: 0.5090\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2500 - accuracy: 0.5120 - val_loss: 0.2500 - val_accuracy: 0.5200\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2500 - accuracy: 0.5090 - val_loss: 0.2498 - val_accuracy: 0.5380\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2498 - accuracy: 0.5360 - val_loss: 0.2493 - val_accuracy: 0.5370\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2494 - accuracy: 0.5450 - val_loss: 0.2488 - val_accuracy: 0.5480\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2492 - accuracy: 0.5550 - val_loss: 0.2482 - val_accuracy: 0.5480\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2485 - accuracy: 0.5570 - val_loss: 0.2482 - val_accuracy: 0.5510\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2479 - accuracy: 0.5540 - val_loss: 0.2469 - val_accuracy: 0.5600\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2473 - accuracy: 0.5560 - val_loss: 0.2467 - val_accuracy: 0.5460\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2467 - accuracy: 0.5580 - val_loss: 0.2455 - val_accuracy: 0.5620\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2464 - accuracy: 0.5490 - val_loss: 0.2448 - val_accuracy: 0.5640\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2450 - accuracy: 0.5670 - val_loss: 0.2450 - val_accuracy: 0.5600\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2430 - accuracy: 0.5880 - val_loss: 0.2438 - val_accuracy: 0.5680\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2432 - accuracy: 0.5820 - val_loss: 0.2443 - val_accuracy: 0.5520\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2427 - accuracy: 0.5810 - val_loss: 0.2431 - val_accuracy: 0.5670\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2414 - accuracy: 0.5890 - val_loss: 0.2432 - val_accuracy: 0.5450\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2419 - accuracy: 0.6010 - val_loss: 0.2424 - val_accuracy: 0.5630\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2397 - accuracy: 0.5860 - val_loss: 0.2417 - val_accuracy: 0.5560\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2376 - accuracy: 0.5920 - val_loss: 0.2410 - val_accuracy: 0.5600\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2356 - accuracy: 0.6020 - val_loss: 0.2400 - val_accuracy: 0.5820\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2365 - accuracy: 0.5990 - val_loss: 0.2372 - val_accuracy: 0.5750\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2334 - accuracy: 0.6060 - val_loss: 0.2305 - val_accuracy: 0.6260\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2330 - accuracy: 0.6100 - val_loss: 0.2326 - val_accuracy: 0.6010\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2311 - accuracy: 0.6300 - val_loss: 0.2317 - val_accuracy: 0.6270\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 2s 60ms/step - loss: 0.2263 - accuracy: 0.6400 - val_loss: 0.2302 - val_accuracy: 0.6280\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2296 - accuracy: 0.6210 - val_loss: 0.2316 - val_accuracy: 0.6180\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2255 - accuracy: 0.6470 - val_loss: 0.2276 - val_accuracy: 0.6240\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2207 - accuracy: 0.6610 - val_loss: 0.2273 - val_accuracy: 0.6220\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2219 - accuracy: 0.6540 - val_loss: 0.2231 - val_accuracy: 0.6410\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2174 - accuracy: 0.6700 - val_loss: 0.2252 - val_accuracy: 0.6340\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 2s 59ms/step - loss: 0.2110 - accuracy: 0.6790 - val_loss: 0.2201 - val_accuracy: 0.6360\n"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    [x_train_1, x_train_2],\n",
    "    labels_train,\n",
    "    validation_data=([x_val_1, x_val_2], labels_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05abdc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NITRO5~1\\AppData\\Local\\Temp/ipykernel_17936/627024544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "new_model= load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946f3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
